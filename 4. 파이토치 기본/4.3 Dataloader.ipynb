{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "transf = tr.Compose([tr.Resize(16), tr.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)\n",
    "\n",
    "print(trainset[0][0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=False)\n",
    "\n",
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAByBJREFUeJzt3cuOVFUUxvFdp6qruqq7qi9A32ggGi4JkJgQExwYJ0x9Bh9CBz6HMfF9jMSBjiSoGBA62Fy06aa7rn2qTp3j2NH6UBL5kv9vvLLOofpjD87K3rtWVVWVADPZ//0CwL9BcGGJ4MISwYUlggtLBBeWCC4sEVxYIriw1FALv/r6G6luqdMOa/LxUOr143d3w5pmd0Xq1T9+LdXVavEgsVbOpV4Hx32pbjybhTWbjbrUa6UT/x696x9KvdZa2rrW2lgOa7JZIfX68ovPpTpWXFgiuLBEcGGJ4MISwYUlggtLBBeWCC4sEVxYkidnDx48kOquXb0a1nRaC9pD6/G0aPfyDanV2c1t7ZkpnpzNpqdSp8FwINUNB/EkcXk0knqdTuMJ1XRpSepVJG1CWOZlWNNtLUq9VKy4sERwYYngwhLBhSWCC0sEF5YILiwRXFiSBxDHfe1j+ngSf5xfavWkXu0sfr2djQ2p1+07d6S6lMVDj7qwvSellFIZf5hPKaViHn/oL4XtPSmllE/jutN8KvWaTCZSXSFsZZpOtWeqWHFhieDCEsGFJYILSwQXlgguLBFcWCK4sERwYUmenF26sCpWxpOzbNaSOt2+ci2s2T57Rup1cKIdtPdiGm8x2epp799d0A6qG46EqZg2hEvrK2thTbtXk3q1cm1aNy3jflmhbXdSseLCEsGFJYILSwQXlgguLBFcWCK4sERwYUkeQDzdfynVLSycxA/d2pJ63bwcn0M2zrUP2wc//SDVPTyKt+Vcuai9/9ay9qH/3q+Pwxp1u82tWx+ENYud+JaclFJ6vve7VDdrr4c1S+KtQR/f2JHqWHFhieDCEsGFJYILSwQXlgguLBFcWCK4sERwYUmenN3/eU+qu34zntxMmitSrycvj8KavwZPpF6P+toU63VjN6zZe96Xep2vHUh1B/34Rp1ZvSv1enx0L6xpNrWtR63BU6kuy+Jp47hsSr0++/Qj7ZlSFfCOIbiwRHBhieDCEsGFJYILSwQXlgguLBFcWJInZ9u7F6W6c7vvhzXF+gWp16syvq7o+7t3pV7V+U+kuuZqvJ9sNNeuUXoy1K7YarbiSdbi8qrU6ySPJ1RFX3v/ZqntTcuK+HC8+lteIllxYYngwhLBhSWCC0sEF5YILiwRXFgiuLAkDyDO7GgDiIlwOFt3ph1UV1ZF/Lwi3jaSUkrny9dSXe3Ft2FN0W1LveoN7eedz+IP+NOXz6Req2X8m/XTXOpVa2v/zqwe31RUjrShh4oVF5YILiwRXFgiuLBEcGGJ4MISwYUlggtLBBeW5MnZybE2eWoLVxG9Pngh9SryYViz2NIOU2s3tPefz+MD6KrDXOq1Po2nWCmlND4bH2iXi9uFlC0yy+I+mvks/i1SSilVvbCkaMbTwTfBigtLBBeWCC4sEVxYIriwRHBhieDCEsGFJYILS/LkrJa065ZK4QC0qqbteZr0T+JeubZ/bf/5H1LduUXh/7JwSF1KKR00xAnVn6/CmmKuTesOc21apyhG8f7BlFKaNeI9Z6lR/49v80+suLBEcGGJ4MISwYUlggtLBBeWCC4sEVxY0gcQc23rRVbFdQ/v/yL1Ojk+CmsG/b7UazrVPqbvZ8KgRdz6ks+1Qct8Gv9m+elY6lVvxFuZFsXD7NSbclbWzoY1W+cvac1ErLiwRHBhieDCEsGFJYILSwQXlgguLBFcWCK4sCRPzgrxiqf9J4/CmvFIm3b1j4/DmtFYO5itKrUpViFMzrJM24ZSr2t1jSxeP+Z17U/VWIjrFtsdqdfKyopUt7UbT8V6q/F07U2w4sISwYUlggtLBBeWCC4sEVxYIriwRHBhSR5AXLr0nlS39+i3+KHih/mWcEZXpmy1SSk1m9rtPM3F+BysXm9V6tURbiBKKaVUi9ePZmtBbCWsRZnWq9NZ0uracV2joT1TxYoLSwQXlgguLBFcWCK4sERwYYngwhLBhSWCC0vy5KyqazfN9M5shjXZgtZrY2M3rGl3V6Ve7eWuVLfcjevW1rVtKN1eT6obj4ZhzUg83K8QDtrL1NPsqkoqOz2Nt3UVxdu7DSglVlyYIriwRHBhieDCEsGFJYILSwQXlgguLBFcWJInZ+Ncm3x0emfCmuXumtSrJewnqzW1KVxNPPSuf/jqrdSklNLm5rZUt7O9E9YsiQftlQ2hTtynd3qaS3Ung2dhzWioHU6oYsWFJYILSwQXlgguLBFcWCK4sERwYYngwpI8gBicHEl1rUbcsj0vpV6VcINMvdR6zWbax/Q8F24Xqmkf8A8PD6S6SR6/WyYcjJdSSoXwe4wnE6nXaKzdtDQYCluPxmOpl4oVF5YILiwRXFgiuLBEcGGJ4MISwYUlggtLBBeWalUlnmwGvENYcWGJ4MISwYUlggtLBBeWCC4sEVxYIriwRHBh6W/fb4Ksm6CVuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oneshot = images[1].permute(1, 2, 0).numpy()    # permute 함수를 통해 순서를 바꿔 채널을 마지막으로 옮김\n",
    "plt.figure(figsize=(2, 2))  # 이미지 사이즈 조절\n",
    "plt.imshow(oneshot) # 이미지 출력\n",
    "plt.axis('off') # 축 제거\n",
    "plt.show()  # 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 클래스 별로 폴더를 정리한 경우\n",
    "\n",
    "# transf = tr.Compose([tr.Resize(128), tr.ToTensor()])\n",
    "# trainset = torchvision.datasets.ImageFolder(root='./class', transform = transf)\n",
    "# trainloader = DataLoader(trainset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정리되지 않은 커스텀 데이터 불러오기\n",
    "\n",
    "train_images = np.random.randint(256, size=(100, 32, 32, 3))/255    # 32x32 크기의 랜덤 RGB 컬러 이미지 100개 생성\n",
    "train_labels = np.random.randint(10, size=(100))    # 100개의 랜덤 레이블 생성, 크기: 0~9\n",
    "\n",
    "class TensorData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        self.x_data = self.x_data.permute(0, 3, 1, 2)\n",
    "        # PyTorch에서는 이미지 데이터를 다룰 때 일반적으로 채널이 두 번째 차원에 위치\n",
    "        # numpy는 채널이 마지막 차원에 위치\n",
    "        self.y_data = torch.LongTensor(y_data)\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorData(train_images, train_labels)\n",
    "train_loader = DataLoader(train_data, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        inputs = torch.FloatTensor(inputs)\n",
    "        inputs = inputs.permute(2, 0, 1)\n",
    "        return inputs, torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutOut:\n",
    "    def __init__(self, ratio=0.5):\n",
    "        self.ratio = int(1/ratio)\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        active = int(np.random.randint(0, self.ratio, 1))\n",
    "\n",
    "        if active == 0:\n",
    "            _, w, h = inputs.size()\n",
    "            min_len = min(w, h)\n",
    "            box_size = int(min_len//4)\n",
    "            idx = int(np.random.randint(0, min_len-box_size, 1))\n",
    "            inputs[:, idx:idx+box_size, idx:idx+box_size] = 0\n",
    "\n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.len = len(y_data)\n",
    "        self.tensor = ToTensor()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = (self.x_data[index], self.y_data[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        else:\n",
    "            sample = self.tensor(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = tr.Compose([ToTensor(), CutOut()])\n",
    "dataset1 = MyDataset(train_images, train_labels, transform = trans)\n",
    "train_loader1 = DataLoader(dataset1, batch_size = 10, shuffle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
